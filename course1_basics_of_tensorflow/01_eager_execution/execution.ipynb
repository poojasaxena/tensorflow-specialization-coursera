{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32304852",
   "metadata": {},
   "source": [
    "# Eager Execution\n",
    "- Here TensorFlow operations are executed by Python, operation by operation, and returning results back to Python.\n",
    "- TensorFlow's eager execution is an imperative programming environment that evaluates operations immediately, without building graphs: operations return concrete values instead of constructing a computational graph to run later. This makes it easy to get started with TensorFlow and debug models, and it reduces boilerplate as well. \n",
    "- To follow along with this guide, run the code samples below in an interactive `python` interpreter.\n",
    "- reference: https://www.tensorflow.org/guide/eager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e43e93",
   "metadata": {},
   "source": [
    "## Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc393db5",
   "metadata": {},
   "source": [
    "### Basic Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2931d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import cProfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698a2546",
   "metadata": {},
   "source": [
    "### enable eagerly execution\n",
    "Enabling eager execution changes how TensorFlow operations behaveâ€”now they immediately evaluate and return their values to Python. `tf.Tensor` objects reference concrete values instead of symbolic handles to nodes in a computational graph. Since there isn't a computational graph to build and run later in a session, it's easy to inspect results using `print()` or a debugger. Evaluating, printing, and checking tensor values does not break the flow for computing gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31f14543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3f5ec0",
   "metadata": {},
   "source": [
    "## Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7157274d",
   "metadata": {},
   "source": [
    "### multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cad19ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2.0]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[2.]]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9075d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.matmul(x,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93e077dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, [[4.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"hello, {}\".format(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ed7a79",
   "metadata": {},
   "source": [
    "### addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cd32b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1,2],\n",
    "                [3,4]])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8531f749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "b = tf.add(a, 1)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef5dee6",
   "metadata": {},
   "source": [
    "### Dynamic control flow\n",
    "A major benefit of eager execution is that all the functionality of the host language is available while your model is executing. So, for example, it is easy to write fizzbuzz:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a942526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fizzbuzz(max_num):\n",
    "    counter = tf.constant(0)\n",
    "    max_num = tf.convert_to_tensor(max_num)\n",
    "    \n",
    "    for num in range(1, max_num.numpy()+1):\n",
    "        num = tf.constant(num)\n",
    "        if int(num%3) ==0 and int(num%5) == 0:\n",
    "            print('FizzBuzz')\n",
    "        elif int(num %3) ==0:\n",
    "            print('Fuzz')\n",
    "        elif int(num %5)==0:\n",
    "            print('Buzz')\n",
    "        else:\n",
    "            print(num.numpy())\n",
    "        counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88631a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "Fuzz\n",
      "4\n",
      "Buzz\n",
      "Fuzz\n",
      "7\n",
      "8\n",
      "Fuzz\n",
      "Buzz\n",
      "11\n",
      "Fuzz\n",
      "13\n",
      "14\n",
      "FizzBuzz\n"
     ]
    }
   ],
   "source": [
    "fizzbuzz(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82237e7a",
   "metadata": {},
   "source": [
    "# tf.functions\n",
    "`tf.function` constructs a `tf.types.experimental.GenericFunction` that executes a TensorFlow graph (`tf.Graph`) created by trace-compiling the TensorFlow operations in func."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44bf1f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def f(x,y):\n",
    "    return x ** 2 +y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de03aaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-30 11:42:52.683138: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([7, 7], dtype=int32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([2,3])\n",
    "y = tf.constant([3, -2])\n",
    "f(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e7aeb8",
   "metadata": {},
   "source": [
    "# Graph\n",
    "- While eager execution has several unique advantages, graph execution enables portability outside Python and tends to offer better performance. Graph execution means that tensor computations are executed as a TensorFlow graph, sometimes referred to as a `tf.Graph` or simply a `graph`.\n",
    "- Graphs are data structures that contain a set of `tf.Operation` objects, which represent units of computation; and `tf.Tensor` objects, which represent the units of data that flow between operations. They are defined in a `tf.Graph` context. Since these graphs are data structures, they can be saved, run, and restored all without the original Python code.\n",
    "- Tensorflow graph representating a 2layers neural network look like when visualized in tensorboard:\n",
    "<div>\n",
    "<img src=\"input_images/graph_2layer_network.jpg\" width=\"700\" height=\"700\" style=\"float:left\"/>\n",
    "</div>\n",
    "- reference: https://www.tensorflow.org/guide/intro_to_graphs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b88062",
   "metadata": {},
   "source": [
    "## Benefits\n",
    "- With a graph, you have a great deal of flexibility. You can use your TensorFlow graph in environments that don't have a Python interpreter, like mobile applications, embedded devices, and backend servers. TensorFlow uses graphs as the format for saved models when it exports them from Python.\n",
    "- Graphs are also easily optimized, allowing the compiler to do transformations like:\n",
    "    - Statically infer the value of tensors by folding constant nodes in your computation (\"constant folding\").\n",
    "    - Separate sub-parts of a computation that are independent and split them between threads or devices.\n",
    "    - Simplify arithmetic operations by eliminating common subexpressions.\n",
    "- There is an entire optimization system, Grappler, to perform this and other speedups.\n",
    "- In short, graphs are extremely useful and let your TensorFlow run fast, run in parallel, and run efficiently on multiple devices. However, you still want to define your machine learning models (or other computations) in Python for convenience, and then automatically construct graphs when you need them.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3537c70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deinf a Python function\n",
    "def a_regular_function(x, y, b):\n",
    "    x = tf.matmul(x, y)\n",
    "    x = x +b\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f01f8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'a_function_that_use_a_graph' is a Tensorflow Function\n",
    "a_function_that_use_a_graph = tf.function(a_regular_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "159adf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = tf.constant([[1.0, 2.0]])\n",
    "y1 = tf.constant([[[2.0], [3.0]]])\n",
    "b1 = tf.constant(4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbb78f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_value = a_regular_function(x1, y1, b1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b437c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_function_value = a_function_that_use_a_graph(x1, y1, b1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "181d47c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On the outside, a Function looks like a regular function you write using TensorFlow operations. \n",
    "## Underneath, however, it is very different. \n",
    "## A Function encapsulates several tf.Graphs behind one API. That is how Function is able to give you the \n",
    "## benefits of graph execution, like speed and deployability.\n",
    "\n",
    "assert(original_value==tf_function_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75d1d38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[12.]]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_function_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15da8c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[12.]]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137829e2",
   "metadata": {},
   "source": [
    "# Graph execution vs Eager Execution\n",
    "The code in a `Function` can be executed both eagerly and as a graph. By default, `Function` executes its code as a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da992833",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Eagerly mode\n",
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ccf73ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Graph\n",
    "@tf.function\n",
    "def get_mse(y_true, y_pred):\n",
    "    sq_diff = tf.pow(y_true,y_pred)\n",
    "    print(\"Calculating MSE\")\n",
    "    return tf.reduce_mean(sq_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fac9c1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([7 3 1 7 5], shape=(5,), dtype=int32)\n",
      "tf.Tensor([1 3 9 4 2], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "y_true = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n",
    "y_pred = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n",
    "print(y_true)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "05fb9f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating MSE\n"
     ]
    }
   ],
   "source": [
    "error=get_mse(y_true, y_pred)\n",
    "error=get_mse(y_true, y_pred)\n",
    "error=get_mse(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d01eaa",
   "metadata": {},
   "source": [
    "### Eagerly to True\n",
    "To verify that your Function's graph is doing the same computation as its equivalent Python function, you can make it execute eagerly with tf.config.run_functions_eagerly(True). This is a switch that turns off Function's ability to create and run graphs, instead executing the code normally.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4206a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Eagerly mode\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "58466e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating MSE\n",
      "Calculating MSE\n",
      "Calculating MSE\n"
     ]
    }
   ],
   "source": [
    "error=get_mse(y_true, y_pred)\n",
    "error=get_mse(y_true, y_pred)\n",
    "error=get_mse(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9949eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
