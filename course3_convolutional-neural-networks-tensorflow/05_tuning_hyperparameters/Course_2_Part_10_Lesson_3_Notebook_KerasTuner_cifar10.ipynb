{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pointed-declaration",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/poojasaxena/tensorflow-developer-zertificate-coursera/blob/main/course2_convolutional-neural-networks-tensorflow/05_tuning_hyperparameters/Course_2_Part_10_Lesson_2_Notebook_KerasTuner_cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "changing-hybrid",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "changing-hybrid",
    "outputId": "b3f9ed51-f3e1-4dd9-f354-a8abab3978d0"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(120000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 120 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 120\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-class",
   "metadata": {
    "id": "unknown-class"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "# Step 1. Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "remarkable-murray",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "remarkable-murray",
    "outputId": "789e1be2-6aa6-418a-d461-474f03e13670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.0\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sticky-morgan",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sticky-morgan",
    "outputId": "92e93fae-85d8-40bb-8bb5-18099724a705"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-fight",
   "metadata": {
    "id": "protective-fight"
   },
   "source": [
    "## Step 2.  KerasTuner Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "oTy91v5uNW-X",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oTy91v5uNW-X",
    "outputId": "b7a77219-400b-49b1-b94b-4982eedb1794"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "\u001b[33mDEPRECATION: Python 3.5 reached the end of its life on September 13th, 2020. Please upgrade your Python as Python 3.5 is no longer maintained. pip 21.0 will drop support for Python 3.5 in January 2021. pip 21.0 will remove support for this functionality.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aE7jjiO9NLn3",
   "metadata": {
    "id": "aE7jjiO9NLn3"
   },
   "outputs": [],
   "source": [
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "roman-therapist",
   "metadata": {
    "id": "roman-therapist"
   },
   "outputs": [],
   "source": [
    "from kerastuner import HyperModel\n",
    "\n",
    "class CustomHyperModel(HyperModel):\n",
    "\n",
    "    def __init__(self, L1=0):\n",
    "        self.L1=L1\n",
    "        \n",
    "    def build(self, hp):\n",
    "        INPUT_SHAPE= (32, 32, 3)\n",
    "        \n",
    "        model = keras.Sequential()        \n",
    "        for i in range(hp.Int('conv_blocks', 3, 5, default=3)):\n",
    "            filters = hp.Int('filters_' + str(i), 32, 256, step=32)\n",
    "            \n",
    "            for _ in range(2):\n",
    "                model.add(keras.layers.Conv2D(filters, kernel_size=(3,3), padding='same', input_shape=INPUT_SHAPE))\n",
    "                model.add(keras.layers.BatchNormalization())\n",
    "                model.add(keras.layers.ReLU())\n",
    "            \n",
    "            if hp.Choice('pooling' + str(i), ['avg', 'max']) == 'max' :\n",
    "                model.add(keras.layers.MaxPooling2D())\n",
    "            else:\n",
    "                model.add(keras.layers.AvgPool2D())\n",
    "        \n",
    "        model.add(keras.layers.GlobalAvgPool2D())\n",
    "        model.add(keras.layers.Dense(hp.Int('hidden_size', 30, 100, step=10, default=50), activation='relu',kernel_regularizer=tf.keras.regularizers.L1(l1=self.L1)))\n",
    "        model.add(keras.layers.Dropout(hp.Float('dropout', 0, 0.5, step=0.1, default=0.5)))\n",
    "        model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "        \n",
    "        model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')), \n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "        print(model.summary())\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-michigan",
   "metadata": {
    "id": "scheduled-michigan"
   },
   "source": [
    "### categorical_crossentropy vs sparse_categorical_crossentropy\n",
    "1. categorical_crossentropy (cce) produces a one-hot array containing the probable match for each category,\n",
    "2. sparse_categorical_crossentropy (scce) produces a category index of the most likely matching category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-house",
   "metadata": {
    "id": "laughing-house"
   },
   "source": [
    "## Step 2.1. Instantiate the tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "premier-oregon",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "premier-oregon",
    "outputId": "3c1264c8-f633-431e-e22f-4ba3845959b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                1650      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 50,064\n",
      "Trainable params: 49,680\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import kerastuner as kt\n",
    "\n",
    "simple_hypermodel = CustomHyperModel()\n",
    "tuner = kt.Hyperband(simple_hypermodel,\n",
    "                    objective='val_accuracy', \n",
    "                    max_epochs=30,\n",
    "                    hyperband_iterations=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-rider",
   "metadata": {
    "id": "twenty-rider"
   },
   "source": [
    "## Step 3. Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-guitar",
   "metadata": {
    "id": "fatal-guitar"
   },
   "source": [
    "### 3.1 tfds dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "leNcu8Dthy1C",
   "metadata": {
    "id": "leNcu8Dthy1C"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '_bz2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5ecdd1b4f7d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cifar10\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow_datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__py2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__init__py3\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__py3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow_datasets/__init__py3.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# needs to happen before anything else, since the imports below will try to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# import tensorflow, too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0mtf_compat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_tf_install\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow_datasets/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# pylint:disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcommunity\u001b[0m  \u001b[0;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madd_data_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow_datasets/core/community/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\"\"\"Community dataset API.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuilder_cls_from_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow_datasets/core/community/load.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataset_builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregistered\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataset_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfile_adapters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow_datasets/core/dataset_info.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msplits\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msplits_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfeature_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtop_level_feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataset_info_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow_datasets/core/features/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_feature\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_feature\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_feature\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mText\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslation_feature\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTranslation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslation_feature\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTranslationVariableLanguages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow_datasets/core/features/text_feature.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtext_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtype_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow_datasets/core/deprecated/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecksums\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madd_checksums_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m __all__ = [\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow_datasets/core/download/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecksums\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madd_checksums_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDownloadConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDownloadManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDownloadError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow_datasets/core/download/download_manager.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchecksums\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkaggle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresource\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresource_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow_datasets/core/download/extractor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\"\"\"Module to use to extract archives. No business logic.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/bz2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthreading\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRLock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0m_bz2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBZ2Compressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBZ2Decompressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '_bz2'"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "data = tfds.load(\"cifar10\")\n",
    "train_ds, test_ds = data[\"train\"], data[\"test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "wJ3msViSiBeS",
   "metadata": {
    "id": "wJ3msViSiBeS"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-22a4010c4406>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstandardize_record\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtest_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstandardize_record\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "def standardize_record(record):\n",
    "    return tf.cast(record[\"image\"], tf.float32) / 255.0, record[\"label\"]\n",
    "\n",
    "\n",
    "train_ds = train_ds.map(standardize_record).cache().batch(64).shuffle(10000)\n",
    "test_ds = test_ds.map(standardize_record).cache().batch(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-progress",
   "metadata": {
    "id": "informed-progress"
   },
   "source": [
    "### 3.2 keras.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "generic-trance",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "generic-trance",
    "outputId": "e57436c9-1e48-4db0-c81b-711f0168362e"
   },
   "outputs": [],
   "source": [
    "(img_train, label_train), (img_test, label_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "registered-phone",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "registered-phone",
    "outputId": "fa035b19-3493-4625-e581-c8b2f41b4b3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of train images:  (50000, 32, 32, 3)\n",
      "No of test images:  (10000, 32, 32, 3)\n",
      "label format for trainig: (50000, 1)\n",
      "label format for testing: (10000, 1)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-523d8ba4eb4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label format for trainig:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label format for testing:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unique lables are :'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "## lets check the number of train/test images\n",
    "print('No of train images: ', img_train.shape)\n",
    "print('No of test images: ', img_test.shape)\n",
    "print('label format for trainig:', label_train.shape)\n",
    "print('label format for testing:', label_test.shape)\n",
    "print('unique lables are :', np.unique(label_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "stretch-force",
   "metadata": {
    "id": "stretch-force"
   },
   "outputs": [],
   "source": [
    "## normalize dataset\n",
    "img_train = img_train.astype('float32')/255.0\n",
    "img_test = img_test.astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-gamma",
   "metadata": {
    "id": "sitting-gamma"
   },
   "source": [
    "# Step 4. Hyperparameter Search\n",
    "* each model will train for at most 30 epochs and 2 iteratios of the Hyperband algo will be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-retailer",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "destroyed-retailer",
    "outputId": "c08369fb-af20-4cf7-d67d-16c8636980c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 64 Complete [01h 21m 10s]\n",
      "val_accuracy: 0.7121000289916992\n",
      "\n",
      "Best val_accuracy So Far: 0.8360000252723694\n",
      "Total elapsed time: 02h 32m 23s\n",
      "\n",
      "Search: Running Trial #65\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "conv_blocks       |5                 |5                 \n",
      "filters_0         |224               |256               \n",
      "pooling0          |max               |avg               \n",
      "filters_1         |32                |192               \n",
      "pooling1          |max               |avg               \n",
      "filters_2         |64                |128               \n",
      "pooling2          |max               |avg               \n",
      "hidden_size       |30                |60                \n",
      "dropout           |0.4               |0.5               \n",
      "learning_rate     |0.0041227         |0.00025273        \n",
      "filters_3         |224               |128               \n",
      "pooling3          |avg               |avg               \n",
      "filters_4         |128               |64                \n",
      "pooling4          |max               |avg               \n",
      "tuner/epochs      |4                 |30                \n",
      "tuner/initial_e...|0                 |10                \n",
      "tuner/bracket     |2                 |3                 \n",
      "tuner/round       |0                 |3                 \n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 224)       6272      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 224)       896       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 32, 32, 224)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 224)       451808    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 224)       896       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 32, 32, 224)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 224)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 32)        64544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 224)         129248    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4, 4, 224)         896       \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 4, 4, 224)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 224)         451808    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4, 4, 224)         896       \n",
      "_________________________________________________________________\n",
      "re_lu_7 (ReLU)               (None, 4, 4, 224)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 2, 2, 224)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 2, 2, 128)         258176    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 2, 2, 128)         512       \n",
      "_________________________________________________________________\n",
      "re_lu_8 (ReLU)               (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 2, 2, 128)         512       \n",
      "_________________________________________________________________\n",
      "re_lu_9 (ReLU)               (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 30)                3870      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                310       \n",
      "=================================================================\n",
      "Total params: 1,583,668\n",
      "Trainable params: 1,580,980\n",
      "Non-trainable params: 2,688\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/4\n",
      "1250/1250 [==============================] - 1116s 892ms/step - loss: 2.1966 - accuracy: 0.1421 - val_loss: 2.0411 - val_accuracy: 0.1811\n",
      "Epoch 2/4\n",
      " 791/1250 [=================>............] - ETA: 6:25 - loss: 2.0726 - accuracy: 0.1748"
     ]
    }
   ],
   "source": [
    "tuner.search(img_train, label_train, epochs=12, validation_split=0.2)\n",
    "# tuner.search(train_ds, validation_data=test_ds, callbacks=[tf.keras.callbacks.EarlyStopping(patience=1)])\n",
    "\n",
    "## get the optimal hyperparameters\n",
    "best_hyperparameters=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\" \n",
    "The Optimal number of units in the first dense layeer is {best_hyperparameters.get('hidden_size')} and \n",
    "the optimal learning rate for the optimal learning_rate is {best_hyperparameters.get('learning_rate')}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ppA_GqWWNoid",
   "metadata": {
    "id": "ppA_GqWWNoid"
   },
   "outputs": [],
   "source": [
    "# Build the model with the optimal hyperparamers and train it on the data for 20 epochs\n",
    "model=tuner.hypermodel.build(best_hyperparameters)\n",
    "history=model.fit(img_train, label_train, epochs=10, validation_split=0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fhUonAypYmsr",
   "metadata": {
    "id": "fhUonAypYmsr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "Course_2_Part_10_Lesson_2_Notebook_KerasTuner_cifar10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
